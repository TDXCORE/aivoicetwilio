# voicebot/bot.py
import os
import asyncio
import json
from typing import Union
from dotenv import load_dotenv
from fastapi import WebSocket, Request, Response
from loguru import logger

from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineTask, PipelineParams
from pipecat.transports.network.fastapi_websocket import (
    FastAPIWebsocketTransport,
    FastAPIWebsocketParams,
)
from pipecat.serializers.twilio import TwilioFrameSerializer
from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.audio.vad.vad_analyzer import VADParams
from pipecat.services.groq.stt import GroqSTTService
from pipecat.services.groq.llm import GroqLLMService
from pipecat.services.elevenlabs.tts import ElevenLabsTTSService
from pipecat.services.openai.tts import OpenAITTSService
from pipecat.processors.aggregators.openai_llm_context import OpenAILLMContext
from openai._types import NOT_GIVEN
from pipecat.frames.frames import TextFrame

# Cargar variables de entorno
load_dotenv(override=True)

def create_ultra_fast_tts_service():
    """Crea el servicio TTS ultra-optimizado para velocidad."""
    
    elevenlabs_api_key = os.getenv("ELEVENLABS_API_KEY")
    openai_api_key = os.getenv("OPENAI_API_KEY")
    
    if elevenlabs_api_key:
        try:
            logger.info("ğŸš€ Configurando ElevenLabs ULTRA-RÃPIDO...")
            tts = ElevenLabsTTSService(
                api_key=elevenlabs_api_key,
                voice_id="qHkrJuifPpn95wK3rm2A",  # ANDREA MEDELLIN COLOMBIA
                model="eleven_flash_v2_5",  # MODELO MÃS RÃPIDO DISPONIBLE
                language="es",
                stability=0.2,  # Menor estabilidad = mayor velocidad
                similarity_boost=0.75,  # Reducido para velocidad
                style=0.2,  # Sin estilo para mayor velocidad
                use_speaker_boost=False,  # Desactivado para velocidad
                output_format="pcm_8000",
                optimize_streaming_latency=4,  # MÃ¡xima optimizaciÃ³n
            )
            logger.info("âœ… ElevenLabs FLASH configurado para mÃ¡xima velocidad")
            return tts, "ElevenLabs-FLASH"
        except Exception as e:
            logger.warning(f"âš ï¸ ElevenLabs fallÃ³: {e}")
    
    # Fallback ultrarrÃ¡pido
    if openai_api_key:
        try:
            logger.info("ğŸš€ Configurando OpenAI TTS ultrarrÃ¡pido...")
            tts = OpenAITTSService(
                api_key=openai_api_key,
                voice="nova",
                model="tts-1",  # Modelo mÃ¡s rÃ¡pido
                language="es",
            )
            logger.info("âœ… OpenAI TTS configurado")
            return tts, "OpenAI-Flash"
        except Exception as e:
            logger.error(f"âŒ OpenAI TTS fallÃ³: {e}")
    
    raise ValueError("âŒ No se pudo configurar TTS")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) PIPELINE ULTRA-OPTIMIZADO
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def _voice_call(ws: WebSocket):
    """Pipeline optimizado para mÃ¡xima velocidad y adaptabilidad."""
    logger.info("ğŸš€ PIPELINE ULTRA-RÃPIDO iniciando...")
    
    try:
        # â”€â”€â”€â”€â”€ TWILIO HANDSHAKE â”€â”€â”€â”€â”€
        start_iter = ws.iter_text()
        await start_iter.__anext__()
        start_msg = await start_iter.__anext__()
        start_data = json.loads(start_msg)
        
        stream_sid = start_data["start"]["streamSid"]
        call_sid = start_data["start"]["callSid"]
        
        logger.info(f"ğŸ“ CallSid: {call_sid}")
        logger.info(f"ğŸ“ StreamSid: {stream_sid}")

        # â”€â”€â”€â”€â”€ SERIALIZER â”€â”€â”€â”€â”€
        serializer = TwilioFrameSerializer(
            stream_sid=stream_sid,
            call_sid=call_sid,
            account_sid=os.getenv("TWILIO_ACCOUNT_SID", ""),
            auth_token=os.getenv("TWILIO_AUTH_TOKEN", ""),
        )
        logger.info("âœ… Twilio serializer creado")

        # â”€â”€â”€â”€â”€ VAD ULTRA-RÃPIDO â”€â”€â”€â”€â”€
        vad_analyzer = SileroVADAnalyzer(
            sample_rate=8000,
            params=VADParams(
                confidence=0.6,      # MÃ¡s agresivo
                start_secs=0.1,      # Respuesta inmediata
                stop_secs=0.3,       # Mucho mÃ¡s rÃ¡pido
                min_volume=0.2       # MÃ¡s sensible
            )
        )
        logger.info("âš¡ VAD ultra-rÃ¡pido configurado")

        # â”€â”€â”€â”€â”€ TRANSPORT OPTIMIZADO â”€â”€â”€â”€â”€
        transport = FastAPIWebsocketTransport(
            websocket=ws,
            params=FastAPIWebsocketParams(
                audio_in_enabled=True,
                audio_out_enabled=True,
                add_wav_header=False,
                vad_analyzer=vad_analyzer,
                serializer=serializer,
                audio_in_sample_rate=8000,
                audio_out_sample_rate=8000,
                audio_in_channels=1,
                audio_out_channels=1,
                audio_out_enabled_timeout=20.0,  # Timeout reducido
            ),
        )
        logger.info("âœ… Transport optimizado")

        # â”€â”€â”€â”€â”€ GROQ STT RÃPIDO â”€â”€â”€â”€â”€
        stt = GroqSTTService(
            api_key=os.getenv("GROQ_API_KEY"),
            model="whisper-large-v3",
            language="es",
            temperature=0,  # MÃ¡xima precisiÃ³n
        )
        logger.info("âœ… Groq STT rÃ¡pido")
        
        # â”€â”€â”€â”€â”€ GROQ LLM OPTIMIZADO â”€â”€â”€â”€â”€
        llm = GroqLLMService(
            api_key=os.getenv("GROQ_API_KEY"), 
            model="llama-3.3-70b-versatile"
        )
        logger.info("âœ… Groq LLM optimizado")
        
        # â”€â”€â”€â”€â”€ TTS ULTRA-RÃPIDO â”€â”€â”€â”€â”€
        tts, tts_provider = create_ultra_fast_tts_service()
        logger.info(f"ğŸš€ TTS configurado: {tts_provider}")

        # â”€â”€â”€â”€â”€ CONTEXTO ADAPTATIVO Y CONCISO â”€â”€â”€â”€â”€
        messages = [
            {
                "role": "system",
                "content": """Guion de Llamada con Soluciones TDX

## *PERSONAJE: Freddy, SDR de TDX*

*PERSONALIDAD Y TONO:*
- *Consultor experto:* Formal-amigable, con la confianza de un par que entiende de tecnologÃ­a y negocio.
- *Ritmo pausado y natural:* Sin muletillas coloquiales excesivas ni groserÃ­as.
- *Escucha activa:* Refleja las ideas del prospecto y conecta con lo que dice.
- *Conciso:* MÃ¡ximo 2 oraciones por respuesta para mantener la fluidez.
- *Lenguaje orientado al beneficio:* Cada intervenciÃ³n se enfoca en el resultado que el lÃ­der obtiene.

*OBJETIVO DE LA LLAMADA:*
1. Descubrir dolores crÃ­ticos del lÃ­der de tecnologÃ­a.
2. Mapearlos a las soluciones de TDX.
3. Concretar una reuniÃ³n de exploraciÃ³n de 25 minutos.

---

### *GUION DE LA LLAMADA*

*APERTURA* (usar SOLO despuÃ©s de que el prospecto hable primero - "Hola", "Buenos dÃ­as", etc.):
"Buen dÃ­a, le habla Freddy, de TDX. Â¿CÃ³mo estÃ¡?"

(ESPERAR RESPUESTA Y RESPONDER CORTÃ‰SMENTE)

*INTRO:*
"QuÃ© bueno. El motivo de mi llamada es muy puntual: muchos lÃ­deres de tecnologÃ­a nos comentan que sus equipos dedican casi un tercio de su tiempo a tareas repetitivas, en lugar de a innovar. De hecho, encontramos un mÃ©todo para devolverles ese tiempo para lo estratÃ©gico."

---

### *DESCUBRIMIENTO*

(usar estas preguntas segÃºn el flujo, asintiendo y conectando con la respuesta del prospecto):

- *Si el prospecto menciona desafÃ­os con tareas repetitivas o carga de equipo:* "Eso que menciona es un reto muy frecuente, lo escucho constantemente en lÃ­deres de TI. Para entender mejor su caso, Â¿dÃ³nde se estÃ¡n generando los *cuellos de botella* que mÃ¡s le quitan foco a su equipo hoy?"

- *Si el prospecto habla de lentitud en proyectos o innovaciÃ³n:* "Totalmente de acuerdo, la velocidad para innovar es crucial hoy en dÃ­a. Pensando en esa agilidad, Â¿cuÃ¡nto tiempo le estÃ¡ tomando a su equipo llevar un nuevo prototipo desde la idea hasta que el usuario final puede interactuar con Ã©l?"

- *Si el prospecto menciona problemas de integraciÃ³n o manualidades:* "Claro, tener los sistemas hablando entre sÃ­ es la base para escalar sin fricciÃ³n. A propÃ³sito de eso, Â¿quÃ© tantos *amarres manuales* tiene que hacer su equipo para que los canales como WhatsApp se entiendan con sus sistemas centrales como el ERP o CRM?"

- *Si el prospecto menciona problemas de atenciÃ³n al cliente o disponibilidad 24/7:* "Entiendo, la atenciÃ³n continua es clave hoy. Â¿CÃ³mo manejan actualmente los picos de consultas o la necesidad de soporte fuera del horario de oficina?"

---

### *SOLUCIONES TDX*

(mapear directamente al dolor identificado, conectando con la necesidad):

- *Para cuellos de botella en soporte (general o digital):* "Justo para ese dolor, con nuestro *AI Chatbot Multiagente por web o WhatsApp, logramos que su equipo se libere de hasta el **ochenta por ciento* de esas consultas repetitivas. AsÃ­ pueden dedicarse a lo que de verdad agrega valor."

- *Para cuellos de botella en soporte telefÃ³nico:* "Para esos momentos donde la lÃ­nea telefÃ³nica se congestiona, nuestro *AI Voice para llamadas telefÃ³nicas* puede gestionar de forma autÃ³noma gran parte de esas interacciones. Esto significa una resoluciÃ³n mÃ¡s rÃ¡pida para el cliente y menos carga para su equipo."

- *Para tareas repetitivas (internas o cara a cliente):* "Entiendo, para *quitarse de encima* esas labores, nuestros *Flujos de AutomatizaciÃ³n* ejecutan esos procesos de forma autÃ³noma. En la prÃ¡ctica, es devolverle horas muy valiosas a su gente para que innoven."

- *Para la velocidad de lanzamiento de MVPs:* "Para acelerar esa salida a producciÃ³n, empaquetamos la soluciÃ³n en nuestro formato de *MVP en quince dÃ­as*. Es la forma mÃ¡s rÃ¡pida de validar sus ideas directamente en el mercado."

- *Para amarres manuales y sistemas desintegrados:* "Precisamente, para eliminar esa fricciÃ³n, nuestras integraciones nativas con CRM y canales como WhatsApp logran que la informaciÃ³n fluya sin reprocesos. Todo conversa de forma automÃ¡tica y natural."

- *Para ofrecer atenciÃ³n visual y personalizada 24/7:* "Si su objetivo es dar una experiencia mÃ¡s inmersiva, nuestros *AI Avatar para llamadas en vivo* pueden interactuar con sus clientes en tiempo real, resolviendo dudas y guiando procesos. Esto libera a su equipo y ofrece atenciÃ³n de alto nivel en todo momento."

- *Para atenciÃ³n al cliente en lÃ­nea (web):* "Para una interacciÃ³n mÃ¡s dinÃ¡mica en su sitio web, nuestro *AI Voice asistente web* puede guiar a los usuarios a travÃ©s de informaciÃ³n compleja o procesos de compra. Esto mejora la experiencia del usuario y reduce la carga de consultas directas a su equipo."

---

### *CIERRE*

"Perfecto, [Nombre del prospecto]. Con base en lo que me comenta sobre [mencionar el dolor principal del prospecto], le propongo algo muy concreto y prÃ¡ctico: tengamos una conversaciÃ³n de *veinticinco minutos* para mostrarle con datos cÃ³mo un cliente con un reto similar al suyo logrÃ³ resultados tangibles. Â¿Le queda bien este *jueves a las diez a.m.* o prefiere el *viernes a primera hora*?"

---

### *MANEJO DE SITUACIONES*

- *Si el usuario dice "No" a las preguntas iniciales:* "Entiendo. Â¿Y hay algÃºn otro tema de eficiencia operativa o agilidad en proyectos que sea importante para usted en este momento?" o "Comprendo. Â¿QuizÃ¡s el tiempo que invierten en tareas de soporte repetitivas podrÃ­a ser un Ã¡rea a mejorar?"
- *Si no entiende una transcripciÃ³n:* "Disculpe, no logrÃ© escucharlo bien, Â¿podrÃ­a repetir por favor?"
- *Si hay silencio prolongado:* "Le pregunto esto porque he visto a muchos lÃ­deres con desafÃ­os similares. Â¿Hay algo que le genere inquietud en este tipo de soluciones?"
- *Nunca quedarse completamente callado,* siempre mantener la conversaciÃ³n activa y consultiva.

---

*INSTRUCCIONES CRÃTICAS:*
- ESPERAR siempre a que el usuario hable primero antes de usar la apertura.
- NO generar respuestas automÃ¡ticas al conectarse.
- Responder SOLO cuando recibas input real del usuario.
- Seguir el guion paso a paso despuÃ©s de que el cliente hable.
- Escuchar 70%, hablar 30%.
- Siempre buscar agendar la reuniÃ³n.
- Usar vocabulario formal-colombiano: "cuello de botella", "amarres", "quitarse de encima".
- Respuestas mÃ¡ximo 2 oraciones para mantener fluidez.
- No incluir caracteres especiales en las respuestas ya que se convertirÃ¡n a audio.
- Ser adaptable y conversacional, mantener el flujo natural"""
            }
        ]
        
        # â”€â”€â”€â”€â”€ CONTEXTO ADAPTATIVO â”€â”€â”€â”€â”€
        context = OpenAILLMContext(messages)
        context_aggregator = llm.create_context_aggregator(context)
        logger.info("âœ… Contexto adaptativo creado")

        # â”€â”€â”€â”€â”€ PIPELINE ULTRA-RÃPIDO â”€â”€â”€â”€â”€
        pipeline = Pipeline([
            transport.input(),
            stt,
            context_aggregator.user(),
            llm,
            tts,
            transport.output(),
            context_aggregator.assistant(),
        ])
        logger.info("âš¡ Pipeline ultra-rÃ¡pido creado")

        # â”€â”€â”€â”€â”€ TASK OPTIMIZADO â”€â”€â”€â”€â”€
        task = PipelineTask(
            pipeline,
            params=PipelineParams(
                audio_in_sample_rate=8000,
                audio_out_sample_rate=8000,
                allow_interruptions=True,
                enable_metrics=True,
                enable_usage_metrics=True,
            ),
        )
        
        # â”€â”€â”€â”€â”€ EVENTOS â”€â”€â”€â”€â”€        
        @transport.event_handler("on_client_connected")
        async def on_client_connected(transport, client):
            logger.info(f"ğŸ”— Cliente conectado: {client}")

        @transport.event_handler("on_client_disconnected")
        async def on_client_disconnected(transport, client):
            logger.info(f"ğŸ‘‹ Cliente desconectado: {client}")
            await task.cancel()

        # â”€â”€â”€â”€â”€ EJECUTAR ULTRA-RÃPIDO â”€â”€â”€â”€â”€
        logger.info(f"ğŸš€ğŸš€ INICIANDO PIPELINE ULTRA-RÃPIDO con {tts_provider}...")
        runner = PipelineRunner(handle_sigint=False)
        await runner.run(task)
        logger.info("ğŸ“ Llamada finalizada")
        
    except Exception as e:
        logger.exception(f"ğŸ’¥ Error: {e}")
        raise


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) SMS OPTIMIZADO
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def _sms(request: Request) -> Response:
    """SMS ultra-conciso."""
    try:
        form = await request.form()
        user_msg = form.get("Body", "") or "..."
        from_number = form.get("From", "")
        
        logger.info(f"ğŸ’¬ SMS de {from_number}: '{user_msg}'")

        llm = GroqLLMService(
            api_key=os.getenv("GROQ_API_KEY"),
            model="llama-3.3-70b-versatile"
        )
        
        context = OpenAILLMContext([
            {
                "role": "system", 
                "content": "Eres Laura, SDR de TDX. Responde en mÃ¡ximo 1 oraciÃ³n, muy concisa. Objetivo: agendar reuniÃ³n."
            },
            {
                "role": "user",
                "content": user_msg
            }
        ])
        
        response = await llm._process_context(context)
        reply = response.choices[0].message.content
        
        logger.info(f"ğŸ¤– SMS conciso: '{reply}'")

        twiml = f'<?xml version="1.0" encoding="UTF-8"?><Response><Message>{reply}</Message></Response>'
        return Response(content=twiml, media_type="text/xml")
        
    except Exception as e:
        logger.exception(f"ğŸ’¥ Error SMS: {e}")
        error_twiml = '<?xml version="1.0" encoding="UTF-8"?><Response><Message>Error</Message></Response>'
        return Response(content=error_twiml, media_type="text/xml")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) HEALTH CHECK ULTRA-OPTIMIZADO
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def health_check():
    """Health check optimizado."""
    logger.info("ğŸ¥ Health check ULTRA-RÃPIDO")
    
    tts_status = "unknown"
    try:
        _, tts_provider = create_ultra_fast_tts_service()
        tts_status = tts_provider
    except Exception as e:
        tts_status = f"error: {str(e)}"
    
    return {
        "status": "healthy", 
        "service": "TDX Laura ULTRA-RÃPIDA",
        "version": "2025-06-25-ULTRA-FAST",
        "location": "MedellÃ­n, Colombia",
        "apis": {
            "groq": bool(os.getenv("GROQ_API_KEY")),
            "elevenlabs": bool(os.getenv("ELEVENLABS_API_KEY")),
            "openai": bool(os.getenv("OPENAI_API_KEY")),
            "twilio": bool(os.getenv("TWILIO_ACCOUNT_SID")),
        },
        "services": {
            "stt": "Groq Whisper Ultra-Fast",
            "llm": "Groq Llama 3.3 (Adaptativo)", 
            "tts": tts_status,
            "voice": "ANDREA MEDELLIN (Flash Mode)",
            "purpose": "Ultra-Fast Adaptive SDR"
        },
        "optimization": {
            "vad_speed": "Ultra-Fast (0.3s stop)",
            "tts_model": "eleven_flash_v2_5",
            "adaptability": "High (responde a feedback)",
            "conciseness": "MÃ¡ximo 1 oraciÃ³n por defecto"
        }
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) ENTRADA PRINCIPAL
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def bot(ctx):
    """Bot ultra-optimizado y adaptativo."""
    if isinstance(ctx, WebSocket):
        logger.info("ğŸš€ LLAMADA ULTRA-RÃPIDA â†’ Laura SDR TDX")
        await _voice_call(ctx)
    elif isinstance(ctx, Request):
        logger.info("ğŸ’¬ SMS ultra-conciso â†’ Laura SDR")
        return await _sms(ctx)
    else:
        logger.error(f"âŒ Tipo no soportado: {type(ctx)}")
        raise TypeError("bot() sÃ³lo acepta WebSocket o Request de FastAPI")