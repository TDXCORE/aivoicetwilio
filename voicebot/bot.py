# voicebot/bot.py
import os
import asyncio
import json
from typing import Union
from dotenv import load_dotenv
from fastapi import WebSocket, Request, Response
from loguru import logger

from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineTask, PipelineParams
from pipecat.transports.network.fastapi_websocket import (
    FastAPIWebsocketTransport,
    FastAPIWebsocketParams,
)
from pipecat.serializers.twilio import TwilioFrameSerializer
from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.services.deepgram.stt import DeepgramSTTService
from pipecat.services.groq.llm import GroqLLMService
from pipecat.services.cartesia.tts import CartesiaTTSService
from pipecat.processors.aggregators.openai_llm_context import OpenAILLMContext
from openai._types import NOT_GIVEN
from pipecat.frames.frames import TextFrame

# Cargar variables de entorno
load_dotenv(override=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) PIPELINE PARA LLAMADAS DE VOZ (WebSocket)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def _voice_call(ws: WebSocket):
    """Maneja la conexiÃ³n Media Streams de Twilio - Deepgram + Groq + Cartesia."""
    logger.info("ğŸ¯ Iniciando pipeline de voz Deepgram + Groq + Cartesia...")
    
    try:
        # â”€â”€â”€â”€â”€ TWILIO HANDSHAKE (necesario para Media Streams) â”€â”€â”€â”€â”€
        start_iter = ws.iter_text()
        await start_iter.__anext__()  # handshake message
        start_msg = await start_iter.__anext__()  # start message
        start_data = json.loads(start_msg)
        
        stream_sid = start_data["start"]["streamSid"]
        call_sid = start_data["start"]["callSid"]
        
        logger.info(f"ğŸ“ CallSid: {call_sid}")
        logger.info(f"ğŸ“ StreamSid: {stream_sid}")

        # â”€â”€â”€â”€â”€ SERIALIZER CON DATOS DE TWILIO (EXACTO COMO EL EJEMPLO) â”€â”€â”€â”€â”€
        serializer = TwilioFrameSerializer(
            stream_sid=stream_sid,
            call_sid=call_sid,
            account_sid=os.getenv("TWILIO_ACCOUNT_SID", ""),
            auth_token=os.getenv("TWILIO_AUTH_TOKEN", ""),
        )
        logger.info("âœ… Twilio serializer creado")

        # â”€â”€â”€â”€â”€ TRANSPORT SIMPLE (COMO EL EJEMPLO QUE FUNCIONA) â”€â”€â”€â”€â”€
        transport = FastAPIWebsocketTransport(
            websocket=ws,
            params=FastAPIWebsocketParams(
                audio_in_enabled=True,
                audio_out_enabled=True,
                add_wav_header=False,
                vad_analyzer=SileroVADAnalyzer(),  # SIN parÃ¡metros extras
                serializer=serializer,
                # REMOVIDO: audio_out_sample_rate, buffering, etc.
            ),
        )
        logger.info("âœ… Transport creado (configuraciÃ³n simple)")

        # â”€â”€â”€â”€â”€ SERVICIOS PRINCIPALES â”€â”€â”€â”€â”€
        # Deepgram STT SIMPLE
        stt = DeepgramSTTService(
            api_key=os.getenv("DEEPGRAM_API_KEY"),
            model="nova-2-general",    
            language="es",             
            # REMOVIDO: smart_format, punctuate, sample_rate
        )
        logger.info("âœ… Deepgram STT creado")
        
        # Groq LLM SIMPLE
        llm = GroqLLMService(
            api_key=os.getenv("GROQ_API_KEY"), 
            model="llama-3.3-70b-versatile"
        )
        logger.info("âœ… Groq LLM creado")
        
        # Cartesia TTS SIMPLE (COMO EL EJEMPLO)
        cartesia_api_key = os.getenv("CARTESIA_API_KEY")
        if not cartesia_api_key:
            logger.error("âŒ CARTESIA_API_KEY no configurada")
            raise ValueError("CARTESIA_API_KEY requerida")
            
        tts = CartesiaTTSService(
            api_key=cartesia_api_key,
            voice_id="308c82e1-ecef-48fc-b9f2-2b5298629789",
            speed=0.75,  # Voz profesional
            # REMOVIDO: output_format, sample_rate, stream_mode, chunk_ms
        )
        logger.info("âœ… Cartesia TTS creado (configuraciÃ³n simple)")

        # â”€â”€â”€â”€â”€ CONTEXTO LLM â”€â”€â”€â”€â”€
    
        messages = [
            {
                "role": "system",
                "content": """Eres Freddy, SDR (Sales Development Representative) de TDX, empresa colombiana de soluciones de IA conversacional y automatizaciÃ³n.

PERSONALIDAD Y TONO:
- Formal-amigable, colombiano profesional
- Sin muletillas coloquiales excesivas ni groserÃ­as
- Ritmo: ~130 palabras/min, pausas cortas
- Escucha activa: refleja las ideas del prospecto
- MÃ¡ximo 2 oraciones por respuesta para mantener fluidez
- Tono relajado y con mucha confianza.

OBJETIVO DE LA LLAMADA:
1) Descubrir dolores crÃ­ticos del lÃ­der de tecnologÃ­a
2) Mapearlos a las soluciones de TDX  
3) Concretar reuniÃ³n de exploraciÃ³n (20-30 min)

GUION A SEGUIR:

APERTURA (usar SOLO despuÃ©s de que el prospecto hable primero y si aun el bot no ha saludado):
"Buen dÃ­a, le habla Freddy, de TDX. Lo estoy contactando porque estamos ayudando a lÃ­deres de tecnologÃ­a a **reducir en un treinta por ciento** el tiempo que sus equipos dedican a tareas repetitivas y a acelerar la salida de prototipos. Â¿Es un tema que estÃ¡ en su radar en este momento?"

DESCUBRIMIENTO (usar estas preguntas segÃºn el flujo):
- "Entendiendo ese desafÃ­o de las tareas repetitivas, Â¿en quÃ© procesos especÃ­ficos su equipo de TI experimenta hoy mÃ¡s **cuellos de botella** por tickets o llamadas que les quitan foco?"
- "Pensando en la agilidad, cuando necesitan lanzar un prototipo o MVP, Â¿cuÃ¡nto tiempo les toma hoy realmente sacarlo a producciÃ³n y llevarlo al usuario final?"
- "Hablando de eficiencia, Â¿sus sistemas como CRM/ERP y canales como WhatsApp o voz conversan de forma fluida, o su equipo debe hacer muchos **amarres manuales** para que funcionen juntos?"

SOLUCIONES TDX (mapear directamente al dolor identificado):
- Para **cuellos de botella** en soporte: "Justamente para liberar esa carga, TDX implementa **AI Chatbot Multiagente** o **AI Voice Assistant**; estas soluciones toman el **ochenta por ciento** de las interacciones repetitivas."
- Para **tareas repetitivas**: "Para **quitarse de encima** esas labores que consumen tiempo valioso, utilizamos **Flujos de AutomatizaciÃ³n** y nuestro **AgentOps Framework**, optimizando procesos end-to-end."
- Para la **velocidad de lanzamiento de MVPs**: "Si el desafÃ­o es la agilidad, con **MVP en quince dÃ­as** y nuestra oferta de **SaaS Agentic**, podemos acelerar significativamente la puesta en marcha de sus innovaciones."
- Para **amarres manuales** y **sistemas desintegrados**: "Si la fricciÃ³n estÃ¡ en la integraciÃ³n, nuestra **IntegraciÃ³n con CRM/ERP** y el **AI Assistant para WhatsApp** permiten una conectividad perfecta y eliminan esos procesos manuales."

CIERRE:
"Dado que identificamos [mencionar el dolor principal del prospecto], propongo una sesiÃ³n de descubrimiento de **veinticinco minutos**. AllÃ­ podemos revisar a detalle sus flujos y le mostrarÃ© un caso real de TDX, similar al suyo, donde logramos resultados tangibles. Â¿Le irÃ­a bien este jueves a las diez a.m. o prefiere el viernes a primera hora?"

INSTRUCCIONES CRÃTICAS:
- Si me interrumpen mientras hablo, parar inmediatamente y escuchar
- Si el usuario dice "Hola" mÃºltiples veces, reconocer que ya me presentÃ©
- Mantener el flujo natural de la conversaciÃ³n sin repetir la apertura
- Si ya hice la apertura, continuar con descubrimiento segÃºn la respuesta
- NO responder hasta que recibas un mensaje del usuario
- Solo responder cuando el cliente haya hablado primero
- Seguir el guion paso a paso despuÃ©s de que el cliente hable
- Escuchar 70%, hablar 30%
- Siempre buscar agendar la reuniÃ³n
- Usar vocabulario formal-colombiano: "cuello de botella", "amarres", "quitarse de encima"
- Respuestas mÃ¡ximo 2 oraciones para mantener fluidez
- No incluir caracteres especiales en las respuestas ya que se convertirÃ¡n a audio"""
            }
        ]
        
        # CONTEXTO SIMPLE (COMO EL EJEMPLO)
        context = OpenAILLMContext(messages)
        context_aggregator = llm.create_context_aggregator(context)
        logger.info("âœ… Contexto de ventas B2B creado")

        # â”€â”€â”€â”€â”€ PIPELINE SIMPLE (EXACTO COMO EL EJEMPLO) â”€â”€â”€â”€â”€
        pipeline = Pipeline([
            transport.input(),           # WebSocket input from client
            stt,                        # Speech-To-Text
            context_aggregator.user(),  # User context
            llm,                        # LLM
            tts,                        # Text-To-Speech
            transport.output(),         # WebSocket output to client
            context_aggregator.assistant(),  # Assistant context
        ])
        logger.info("âœ… Pipeline creado (configuraciÃ³n simple)")

        # â”€â”€â”€â”€â”€ TASK SIMPLE (COMO EL EJEMPLO) â”€â”€â”€â”€â”€
        task = PipelineTask(
            pipeline,
            params=PipelineParams(
                audio_in_sample_rate=8000,
                audio_out_sample_rate=8000,
                enable_metrics=True,
                allow_interruptions=True,
                enable_usage_metrics=True,
                # REMOVIDO: allow_interruptions y otros parÃ¡metros
            ),
        )
        
        # â”€â”€â”€â”€â”€ EVENTOS SIMPLES (COMO EL EJEMPLO) â”€â”€â”€â”€â”€        
        @transport.event_handler("on_client_connected")
        async def on_client_connected(transport, client):
            logger.info(f"ğŸ”— Cliente conectado: {client}")
            
         

        @transport.event_handler("on_client_disconnected")
        async def on_client_disconnected(transport, client):
            logger.info(f"ğŸ‘‹ Cliente desconectado: {client}")
            await task.cancel()

        # â”€â”€â”€â”€â”€ EJECUTAR RUNNER (EXACTO COMO EL EJEMPLO) â”€â”€â”€â”€â”€
        logger.info("ğŸš€ Iniciando pipeline de ventas B2B...")
        runner = PipelineRunner(handle_sigint=False, force_gc=True)
        await runner.run(task)
        logger.info("ğŸ“ Llamada de ventas finalizada")
        
    except Exception as e:
        logger.exception(f"ğŸ’¥ Error en pipeline de ventas: {e}")
        raise


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) PIPELINE SMS / WHATSAPP (webhook HTTP)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def _sms(request: Request) -> Response:
    """Maneja mensajes SMS/WhatsApp de Twilio - Groq LLM."""
    try:
        form = await request.form()
        user_msg = form.get("Body", "") or "..."
        from_number = form.get("From", "")
        
        logger.info(f"ğŸ’¬ SMS de {from_number}: '{user_msg}'")

        # Usar Groq Llama para respuesta de texto
        llm = GroqLLMService(
            api_key=os.getenv("GROQ_API_KEY"),
            model="llama-3.3-70b-versatile"
        )
        
        # Contexto simple para SMS
        context = OpenAILLMContext([
            {
                "role": "system", 
                "content": "Eres Freddy, SDR de TDX. Responde de forma concisa y profesional en espaÃ±ol. EnfÃ³cate en agendar una reuniÃ³n para mostrar nuestras soluciones de IA conversacional."
            },
            {
                "role": "user",
                "content": user_msg
            }
        ])
        
        # Generar respuesta
        response = await llm._process_context(context)
        reply = response.choices[0].message.content
        
        logger.info(f"ğŸ¤– Respuesta SMS: '{reply}'")

        # TwiML para responder
        twiml = f'<?xml version="1.0" encoding="UTF-8"?><Response><Message>{reply}</Message></Response>'
        return Response(content=twiml, media_type="text/xml")
        
    except Exception as e:
        logger.exception(f"ğŸ’¥ Error en SMS: {e}")
        error_twiml = '<?xml version="1.0" encoding="UTF-8"?><Response><Message>Error procesando mensaje</Message></Response>'
        return Response(content=error_twiml, media_type="text/xml")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) HEALTH CHECK
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def health_check():
    """Health check endpoint."""
    logger.info("ğŸ¥ Health check Pipeline de Ventas B2B")
    return {
        "status": "healthy", 
        "service": "TDX Sales Bot - Deepgram + Groq + Cartesia",
        "version": "2025-06-24-SALES-B2B-SIMPLE",
        "apis": {
            "deepgram": bool(os.getenv("DEEPGRAM_API_KEY")),
            "groq": bool(os.getenv("GROQ_API_KEY")),
            "cartesia": bool(os.getenv("CARTESIA_API_KEY")),
            "twilio": bool(os.getenv("TWILIO_ACCOUNT_SID")),
        },
        "services": {
            "stt": "Deepgram Nova-2 Simple",
            "llm": "Groq Llama 3.3 70B Simple", 
            "tts": "Cartesia Simple",
            "purpose": "Sales Development Representative (SDR)"
        }
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) PUNTO ÃšNICO DE ENTRADA
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def bot(ctx):
    """
    FunciÃ³n principal para Sales Bot B2B.
    Compatible con tu main.py existente.
    """
    if isinstance(ctx, WebSocket):
        logger.info("ğŸ“ Llamada de ventas â†’ Freddy SDR de TDX")
        await _voice_call(ctx)
    elif isinstance(ctx, Request):
        logger.info("ğŸ’¬ Mensaje SMS/WhatsApp â†’ Freddy SDR")
        return await _sms(ctx)
    else:
        logger.error(f"âŒ Tipo no soportado: {type(ctx)}")
        raise TypeError("bot() sÃ³lo acepta WebSocket o Request de FastAPI")